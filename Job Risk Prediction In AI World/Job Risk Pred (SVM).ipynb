{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 13670314,
          "sourceType": "datasetVersion",
          "datasetId": 8692100
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebookaefffd7fde",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "khushikyad001_ai_impact_on_jobs_2030_path = kagglehub.dataset_download('khushikyad001/ai-impact-on-jobs-2030')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "RBvXt9uT_8pz"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T06:09:19.002442Z",
          "iopub.execute_input": "2025-12-09T06:09:19.003256Z",
          "iopub.status.idle": "2025-12-09T06:09:19.010761Z",
          "shell.execute_reply.started": "2025-12-09T06:09:19.003225Z",
          "shell.execute_reply": "2025-12-09T06:09:19.009867Z"
        },
        "id": "5LGuMzGI_8p6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/ai-impact-on-jobs-2030/AI_Impact_on_Jobs_2030.csv')\n",
        "df.sample(6)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T06:09:19.011842Z",
          "iopub.execute_input": "2025-12-09T06:09:19.012142Z",
          "iopub.status.idle": "2025-12-09T06:09:19.039858Z",
          "shell.execute_reply.started": "2025-12-09T06:09:19.012089Z",
          "shell.execute_reply": "2025-12-09T06:09:19.039046Z"
        },
        "id": "HxVXLdpt_8p7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Quality Check"
      ],
      "metadata": {
        "id": "qqRJaeLX_8p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T06:09:19.041343Z",
          "iopub.execute_input": "2025-12-09T06:09:19.041927Z",
          "iopub.status.idle": "2025-12-09T06:09:19.052555Z",
          "shell.execute_reply.started": "2025-12-09T06:09:19.041903Z",
          "shell.execute_reply": "2025-12-09T06:09:19.051791Z"
        },
        "id": "ND-cqJhS_8p9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T06:09:19.053442Z",
          "iopub.execute_input": "2025-12-09T06:09:19.053678Z",
          "iopub.status.idle": "2025-12-09T06:09:19.091952Z",
          "shell.execute_reply.started": "2025-12-09T06:09:19.053659Z",
          "shell.execute_reply": "2025-12-09T06:09:19.091203Z"
        },
        "id": "v-LPxDK4_8p-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next...\n",
        "1) Missing Values Check.\n",
        "2) Visualization of Missing Values.\n",
        "3) Duplicates Check.\n",
        "4) Initial Visualization of Key Numerical Distributions.\n",
        "\n",
        "Graph Info.\n",
        "**Average Salary** appears to be fairly normally distributed but slightly bimodal, indicating two main clusters of salaries.\n",
        "**Years of Experience** is also widely distributed, suggesting jobs cover both entry-level and very senior positions."
      ],
      "metadata": {
        "id": "w8BExm_3_8qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0].sort_values(ascending=False)\n",
        "\n",
        "if missing_values.empty:\n",
        "    print(\"\\nNo missing values found in the dataset.\")\n",
        "else:\n",
        "    print(\"\\nMissing Values per Column:\")\n",
        "    print(missing_values.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=missing_values.index, y=missing_values.values)\n",
        "    plt.title('Missing Values Count per Column')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xlabel('Columns')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show\n",
        "\n",
        "\n",
        "duplicates_count = df.duplicated().sum()\n",
        "print(f\"\\nNumber of duplicate rows: {duplicates_count}\")\n",
        "\n",
        "\n",
        "numerical_cols = ['Average_Salary', 'Years_Experience']\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    sns.histplot(df[col], kde=True, ax=axes[i], bins=20, color='skyblue')\n",
        "    axes[i].set_title(f'Distribution of {col}', fontsize=12)\n",
        "    axes[i].set_xlabel(col, fontsize=10)\n",
        "    axes[i].set_ylabel('Frequency', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T06:09:19.093634Z",
          "iopub.execute_input": "2025-12-09T06:09:19.093907Z",
          "iopub.status.idle": "2025-12-09T06:09:19.790449Z",
          "shell.execute_reply.started": "2025-12-09T06:09:19.093886Z",
          "shell.execute_reply": "2025-12-09T06:09:19.789488Z"
        },
        "id": "Hz4HEQeb_8qC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning is not required**"
      ],
      "metadata": {
        "id": "Q4SCxQlE_8qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "lE_d-PxZ_8qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1) How does the Average_Salary vary across different Education_Levels? (Box Plot)**\n",
        "\n",
        "**ans-** There is a clear positive trend: higher education levels generally correlate with higher average salaries.\n",
        "\n",
        "**Q2) What is the distribution of jobs across the different Risk_Category groups? (Count Plot)**\n",
        "\n",
        "**ans-** The Medium risk category contains the largest number of jobs ($\\mathbf{1,521}$), suggesting that over half the jobs fall into a moderate risk level concerning the impact of AI.The High ($\\mathbf{740}$) and Low ($\\mathbf{739}$) risk categories are almost equally distributed, with slightly fewer jobs than the medium risk category.\n",
        "\n",
        "**Q3) Is there a correlation between Years_Experience and Average_Salary? (Scatter Plot)**\n",
        "\n",
        "**ans-** The scatter plot shows a weak positive correlation between Years_Experience and Average_Salary.\n",
        "\n",
        "**Q4) How does the Automation_Probability_2030 relate to the Risk_Category? (Box Plot)**\n",
        "\n",
        "**ans-** The Risk_Category strongly aligns with the Automation_Probability_2030:Low Risk jobs have a median automation probability near $\\mathbf{0.2}$.Medium Risk jobs have a median probability near $\\mathbf{0.5}$.High Risk jobs have the highest median probability, near $\\mathbf{0.8}$, confirming the risk categorization is based heavily on this automation metric.\n",
        "\n",
        "**Q5) Which jobs have the highest and lowest average AI_Exposure_Index? (Top/Bottom 10 Bar Chart)**\n",
        "\n",
        "**ans-** Highest AI Exposure (Red Bars): Jobs like Graphic Designer, Construction Worker, and Delivery Driver top the list. This suggests these jobs frequently interact with or rely on tasks that are heavily impacted by current AI technology.\n",
        "Lowest AI Exposure (Green Bars): Jobs like Research Scientist, Data Analyst, and Teacher are at the bottom. This might indicate that the core tasks of these roles require complex, nuanced human interaction or are not yet easily quantifiable by the AI Exposure Index.\n",
        "\n"
      ],
      "metadata": {
        "id": "oHoy9gk1_8qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "education_order = [\"High School\", \"Bachelor's\", \"Master's\", \"PhD\"]\n",
        "risk_order = [\"Low\", \"Medium\", \"High\"]\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Education_Level', y='Average_Salary', data=df, order=education_order, palette='viridis')\n",
        "plt.title('Q1) Average Salary Distribution by Education Level')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Average Salary')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Risk_Category', data=df, order=risk_order, palette='magma')\n",
        "plt.title('Q2) Job Count by Risk Category')\n",
        "plt.xlabel('Risk Category')\n",
        "plt.ylabel('Number of Jobs')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Years_Experience', y='Average_Salary', data=df, alpha=0.6)\n",
        "sns.regplot(x='Years_Experience', y='Average_Salary', data=df, scatter=False, color='red')\n",
        "plt.title('Q3) Correlation between Years of Experience and Average Salary')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Average Salary')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Risk_Category', y='Automation_Probability_2030', data=df, order=risk_order, palette='cividis')\n",
        "plt.title('Q4) Automation Probability by Risk Category')\n",
        "plt.xlabel('Risk Category')\n",
        "plt.ylabel('Automation Probability (2030)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "avg_ai_exposure = df.groupby('Job_Title')['AI_Exposure_Index'].mean().sort_values(ascending=False)\n",
        "top_10_ai = avg_ai_exposure.head(10)\n",
        "bottom_10_ai = avg_ai_exposure.tail(10)\n",
        "combined_ai_exposure = pd.concat([top_10_ai, bottom_10_ai])\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = ['red'] * 10 + ['green'] * 10\n",
        "sns.barplot(x=combined_ai_exposure.values, y=combined_ai_exposure.index, palette=colors)\n",
        "plt.title('Q5) Top 10 Highest and Bottom 10 Lowest Average AI Exposure Index by Job Title')\n",
        "plt.xlabel('Average AI Exposure Index')\n",
        "plt.ylabel('Job Title')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T06:09:19.791378Z",
          "iopub.execute_input": "2025-12-09T06:09:19.791627Z",
          "iopub.status.idle": "2025-12-09T06:09:21.376144Z",
          "shell.execute_reply.started": "2025-12-09T06:09:19.791608Z",
          "shell.execute_reply": "2025-12-09T06:09:21.375281Z"
        },
        "id": "oHG_n1os_8qE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering and Model Training\n",
        "Model- Support Vector Machine Classifier"
      ],
      "metadata": {
        "id": "iQGzo0SN_8qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(df['Risk_Category'])\n",
        "X = df.drop('Risk_Category', axis=1)\n",
        "\n",
        "categorical_features = ['Education_Level', 'Job_Title']\n",
        "numerical_features = X.columns.drop(categorical_features).tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('scaler', StandardScaler(), numerical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "#Model\n",
        "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "svc_model = SVC(kernel='rbf', random_state=42, class_weight='balanced')\n",
        "svc_model.fit(X_train_processed, y_train_encoded)\n",
        "\n",
        "y_pred_encoded = svc_model.predict(X_test_processed)\n",
        "\n",
        "y_pred_encoded = svc_model.predict(X_test_processed)\n",
        "\n",
        "final_accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
        "\n",
        "print(f\"\\n Test Set Accuracy: {final_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T06:09:21.376941Z",
          "iopub.execute_input": "2025-12-09T06:09:21.377262Z",
          "iopub.status.idle": "2025-12-09T06:09:21.64472Z",
          "shell.execute_reply.started": "2025-12-09T06:09:21.37724Z",
          "shell.execute_reply": "2025-12-09T06:09:21.643854Z"
        },
        "id": "Rm6iS2kQ_8qF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "AI Job Risk Prediction\n",
        "The goal was to perform Multi-Class Classification to predict the Risk Category (Low, Medium, or High) of a job based on its attributes.\n",
        "\n",
        "1. Data Quality and Exploratory Analysis (EDA)-\n",
        "\n",
        "**Data Quality:** The dataset ($\\mathbf{3,000}$ rows) was found to be exceptionally clean, requiring no imputation (zero missing values) or duplicate removal.\n",
        "**Key EDA Insight:** Exploratory analysis confirmed a very strong relationship between the target variable, Risk_Category, and predictive features like Automation_Probability_2030 and AI_Exposure_Index.\n",
        "\n",
        "2. Feature Engineering and Preprocessing-\n",
        "Due to the nature of the Support Vector Machine (SVC) algorithm, several critical preprocessing steps were required:\n",
        "\n",
        "Target Label Encoding (Essential): The string labels in the target variable, $\\mathbf{Y}$ (Risk_Category), were converted to numerical integers ($0, 1, 2$) using LabelEncoder, as required by $\\text{SVC}$ for multi-class tasks.\n",
        "\n",
        "Categorical Encoding: Features like Job_Title and Education_Level were converted into a machine-readable format using OneHotEncoder.\n",
        "\n",
        "Numerical Scaling (Crucial for SVM): All numerical features (including Average_Salary, Years_Experience, and all Skill_ columns) were normalized using StandardScaler. This step ensures that distance-based calculations, which $\\text{SVC}$ relies on, are not dominated by features with larger scales.\n",
        "\n",
        "3. Model Training and Evaluation:\n",
        "\n",
        "Support Vector Classifier (SVC)The $\\text{SVC}$ model was trained on the processed data ($80\\%$ train, $20\\%$ test split).\n",
        "   \n",
        "The near-perfect accuracy strongly suggests that the Risk_Category is defined by clear, quantifiable rules (likely thresholds on Automation_Probability_2030 and AI_Exposure_Index), which the powerful $\\text{SVC}$ model was able to perfectly capture and generalize.\n",
        "\n",
        "4. Model Choice and Real-World Accuracy\n",
        "Why the Support Vector Machine (SVM) was Chosen?\n",
        "\n",
        "The Support Vector Machine (implemented as SVC) was an excellent choice for this multi-class classification problem for two key reasons:\n",
        "\n",
        "**High-Dimensional Space:** After using One-Hot Encoding on categorical features (Job_Title, Education_Level), the dataset became high-dimensional. SVMs are mathematically designed to find the optimal separation boundary (hyperplane) that maximizes the margin between classes in high-dimensional spaces, making them very effective here.\n",
        "\n",
        "**Strong Generalization:** SVMs are known for strong generalization capability. When paired with the necessary Standard Scaling of numerical features, the model is highly robust, avoiding common pitfalls like overfitting to minor noisy data points.\n",
        "\n",
        "The observed accuracy of $\\mathbf{99.33\\%}$ is likely**overstated**compared to what would be achieved in the real world.\n",
        "The high accuracy proves the features are extremely strong predictors, but expect some degradation when applying the model to messy, unlabeled, real-world data."
      ],
      "metadata": {
        "id": "Utsf5BwZ_8qF"
      }
    }
  ]
}